# Data Cleaning & Preprocessing - AI & ML Internship Task 1

## Overview
This project demonstrates data cleaning and preprocessing on the Titanic dataset, including handling missing values, encoding categorical variables, normalization, and outlier removal.

## Tools Used
- Python, Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn (MinMaxScaler)

## Key Steps
- Explored dataset and handled missing values (median for numerical, mode for categorical).
- Dropped 'Cabin' column due to excessive missing data.
- Converted categorical columns ('Sex', 'Embarked') using one-hot encoding.
- Applied Min-Max normalization to numerical features ('Age', 'Fare').
- Visualized and removed outliers from 'Fare' using boxplots and IQR method.

## Usage
Run the Jupyter notebook `Data Cleaning & Preprocessing.ipynb` to replicate the preprocessing steps.

---

Thank you for reviewing this project.
